Purpose: prove ML is bounded, calibrated, and safely reversible

ML is optional; system defaults to rules under uncertainty

- How to reproduce training + evaluation
- Where calibration plots are
- How abstention works
- How fallback works
- What triggers rollback

Deliverables

- Label logic (two labels)
- Time-based splits dataset builder
- Logistic baseline vs rules metrics
- Tree model comparison
- Calibration plots
- Abstention (“no-predict”) zones
- Drift detection on features + predictions
- Automatic fallback to rules
- Simulated bad data → safe degradation
- Lifecycle + rollback doc
